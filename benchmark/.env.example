# Copy to `benchmark/.env` (or run from `benchmark/` and copy to `.env`) and fill in values.
#
# Provider-agnostic defaults (OpenAI-compatible Chat Completions):
SMI_PROVIDER=openai_compatible
SMI_API_KEY=REPLACE_ME
SMI_MODEL=REPLACE_ME
SMI_API_BASE_URL=https://api.openai.com/v1

# Optional knobs:
SMI_TEMPERATURE=0
SMI_MAX_TOKENS=2048

# Optional: Phase II tx simulation defaults.
# Set these if you want dry-run (ground truth) to work out-of-the-box.
#
# SECURITY WARNING: NEVER put your private key in this file. 
# The benchmarks only use the `dry-run` API, which requires your 
# PUBLIC ADDRESS only. It does not need to sign transactions.
#
# - SMI_SENDER should be your PUBLIC ADDRESS (0x...) that owns 
#   at least one Coin<SUI> on the target network.
#   REQUIRED for --simulation-mode dry-run (execution scoring).
# - SMI_GAS_COIN can optionally pin a specific gas coin object id (otherwise the runner picks one).
SMI_SENDER=
SMI_GAS_COIN=

# Optional: provider-specific knobs.
#
# Z.AI supports a `thinking` parameter (GLM-4.7). The Coding Plan endpoint enables
# “Preserved Thinking” by default; for our single-turn benchmark calls we usually
# want to clear it.
#
# SMI_THINKING=enabled|disabled
# SMI_CLEAR_THINKING=true|false
#
# Z.AI also supports Structured Output (JSON mode). We recommend enabling it so
# the model reliably returns parseable JSON.
#
# SMI_RESPONSE_FORMAT=json_object

# If your provider is not OpenAI, set SMI_API_BASE_URL to that provider’s
# OpenAI-compatible base URL (it must support POST /chat/completions).
#
# Z.AI example (GLM-4.7):
# - If you have a Z.AI “Model API” resource package, use:
#   SMI_API_BASE_URL=https://api.z.ai/api/paas/v4
# - If you have a Z.AI “GLM Coding Plan” subscription, use the dedicated coding endpoint:
#   SMI_API_BASE_URL=https://api.z.ai/api/coding/paas/v4
# SMI_MODEL=glm-4.7
# SMI_THINKING=enabled
# SMI_CLEAR_THINKING=true
# SMI_RESPONSE_FORMAT=json_object
